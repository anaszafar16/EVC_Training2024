{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification\n",
        "Create a classifier using pre-trained model (ResNet).\n",
        "\n",
        "You have to make a Dataset class before training, then evaluate the model. Create another classifier using (LeNet)\n",
        "\n",
        "\n",
        "Transfer Learinig: https://www.youtube.com/watch?v=K0lWSB2QoIQ\n",
        "\n",
        "ResNet: https://towardsdatascience.com/understanding-and-visualizing-resnets-442284831be8\n",
        "\n",
        "LeNet: https://medium.com/@siddheshb008/lenet-5-architecture-explained-3b559cb2d52b\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/mahmoudreda55/satellite-image-classification\n"
      ],
      "metadata": {
        "id": "YOGbBN_qzqyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "MkKY5mHeY3b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZrXZABuzPyo"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets\n",
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download mahmoudreda55/satellite-image-classification\n",
        "!unzip /content/satellite-image-classification.zip\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3yZzAaJ2a7EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Handling"
      ],
      "metadata": {
        "id": "5gWY5IJbiRJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(os.listdir(root_dir))  # Get the folder names and sort them\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Iterate through each class directory and collect image paths and labels\n",
        "        for label, class_name in enumerate(self.classes):\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            for img_path in glob.glob(os.path.join(class_dir, '*')):\n",
        "                self.image_paths.append(img_path)\n",
        "                self.labels.append(label)\n",
        "\n",
        "        # Shuffle the dataset\n",
        "        combined = list(zip(self.image_paths, self.labels))\n",
        "        random.shuffle(combined)\n",
        "        self.image_paths[:], self.labels[:] = zip(*combined)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "39WI94_mc6_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224 as required by ResNet\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize as required by ResNet\n",
        "])\n",
        "\n",
        "# Initialize the dataset\n",
        "dataset = CustomImageDataset(root_dir='data', transform=transform)"
      ],
      "metadata": {
        "id": "LOtCVfYDdbL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
      ],
      "metadata": {
        "id": "LxZAfkMcefwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=b_size, shuffle=True)\n",
        "val_loader =   DataLoader(val_dataset, batch_size=b_size)\n",
        "test_loader =  DataLoader(test_dataset, batch_size=b_size)"
      ],
      "metadata": {
        "id": "k2FYkHJRefs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet Modle"
      ],
      "metadata": {
        "id": "Bf9cBCHMid-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "gwObD2xtjqyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)  # Use ResNet-18 and pretrained weights\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(dataset.classes))  # Modify the final layer to match the number of classes --> 4\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txi7M05Qj544",
        "outputId": "3109b7f0-2c13-49af-9e94-42c19dca6a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 82.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "EPzkJvjkefo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    train_losses.append(epoch_loss)\n",
        "    training_accuracy = 100 * correct / total\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(val_dataset)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f} - Train Accuracy: {training_accuracy:.2f}% - Val Loss: {val_loss:.4f} - Val Accuracy: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_8o2EXjefmk",
        "outputId": "416822ea-4028-4c11-f529-f3f2155fdf1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.4005 - Train Accuracy: 88.85% - Val Loss: 0.1134 - Val Accuracy: 98.40%\n",
            "Epoch 2/10, Train Loss: 0.1118 - Train Accuracy: 97.69% - Val Loss: 0.0604 - Val Accuracy: 99.29%\n",
            "Epoch 3/10, Train Loss: 0.0820 - Train Accuracy: 98.00% - Val Loss: 0.0440 - Val Accuracy: 99.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training and validation losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, num_epochs+1), val_losses, label='Val Loss')\n",
        "plt.title(f'Training and Validation Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-QWUn1AGdZ-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss = test_loss / len(test_dataset)\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "print('Training and evaluation complete')"
      ],
      "metadata": {
        "id": "NFqrorWkljVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot sample of predictions"
      ],
      "metadata": {
        "id": "OvXIHFqV47v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Load a batch from DataLoader\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.to(device)\n",
        "\n",
        "# Example: Apply model to batch of images\n",
        "outputs = model(images)\n",
        "_, predicted = torch.max(outputs.data, 1)  # Get the index of the class with the highest probability\n",
        "\n",
        "# Mean and std for normalization (as used in training)\n",
        "mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
        "std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
        "\n",
        "# Function to denormalize a single image tensor\n",
        "def denormalize(image_tensor):\n",
        "    return torch.clamp(image_tensor * std[:, None, None] + mean[:, None, None], 0, 1)\n",
        "\n",
        "# Denormalize images\n",
        "images_denorm = [denormalize(images[i]) for i in range(images.shape[0])]\n",
        "\n",
        "# Convert tensors to numpy arrays for plotting\n",
        "images_np = [img.cpu().numpy() for img in images_denorm]\n",
        "labels_true = labels.cpu().numpy()\n",
        "labels_pred = predicted.cpu().numpy()\n",
        "\n",
        "# Create a grid of images\n",
        "num_images = len(images_np)\n",
        "rows = int(np.sqrt(num_images))\n",
        "cols = num_images // rows if num_images % rows == 0 else num_images // rows + 1"
      ],
      "metadata": {
        "id": "NPFnvckR4t2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(rows, cols, figsize=(13, 10))\n",
        "if labels_pred is None:\n",
        "    labels_pred = labels_true\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < num_images:\n",
        "        # Plot image\n",
        "        ax.imshow(np.transpose(images_np[i], (1, 2, 0)))\n",
        "        ax.axis('off')\n",
        "        pre_class_name = dataset.classes[labels_pred[i]]\n",
        "        true_class_name = dataset.classes[labels_true[i]]\n",
        "        # Show true and predicted labels\n",
        "        ax_title = f\"True: {true_class_name} \\nPredicted: {pre_class_name}\"\n",
        "        ax.set_title(ax_title)\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f3s2HRp84MBm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}